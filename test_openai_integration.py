#!/usr/bin/env python3
"""
Test per verificare l'integrazione con OpenAI
"""
import asyncio
import websockets
import json
import base64
import logging
import os
from dotenv import load_dotenv

# Carica le variabili d'ambiente
load_dotenv()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_openai_integration():
    """Test dell'integrazione OpenAI"""
    
    # Verifica che la chiave API sia configurata
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key == "sk-your-openai-api-key-here":
        print("‚ùå OPENAI_API_KEY non configurata!")
        print("Crea un file .env con la tua chiave API di OpenAI:")
        print("OPENAI_API_KEY=sk-your-actual-key-here")
        return False
    
    print("üîç Test Integrazione OpenAI")
    print("=" * 50)
    
    uri = "ws://localhost:8000/"
    
    try:
        async with websockets.connect(uri) as websocket:
            print("‚úÖ 1. Connessione WebSocket stabilita")
            
            # Test evento connected
            connected_msg = {"event": "connected", "streamSid": "test-openai-123"}
            await websocket.send(json.dumps(connected_msg))
            print("‚úÖ 2. Evento 'connected' inviato")
            await asyncio.sleep(0.5)
            
            # Test pacchetti audio che simulano parlato
            # Generiamo audio che il VAD dovrebbe riconoscere come parlato
            for i in range(10):  # Pi√π pacchetti per simulare parlato
                # Genera audio con pattern che simula parlato (variazioni)
                test_audio = bytes([128 + (i * 15) % 128] * 160)  # Pattern variabile
                audio_msg = {
                    "event": "media",
                    "streamSid": "test-openai-123",
                    "media": {"payload": base64.b64encode(test_audio).decode('utf-8')}
                }
                await websocket.send(json.dumps(audio_msg))
                print(f"‚úÖ 3.{i+1} Pacchetto audio {i+1} inviato")
                await asyncio.sleep(0.1)
            
            # Simula silenzio per attivare il VAD
            print("‚úÖ 4. Simulazione silenzio per attivare VAD...")
            await asyncio.sleep(2)  # Aspetta che il VAD rilevi la fine del parlato
            
            # Test evento stop
            stop_msg = {"event": "stop", "streamSid": "test-openai-123"}
            await websocket.send(json.dumps(stop_msg))
            print("‚úÖ 5. Evento 'stop' inviato")
            await asyncio.sleep(0.5)
            
            print("\nüéâ TEST COMPLETATO!")
            print("=" * 50)
            print("‚úÖ Connessione WebSocket funzionante")
            print("‚úÖ Eventi audio processati")
            print("‚úÖ VAD dovrebbe aver rilevato il parlato")
            print("‚úÖ OpenAI dovrebbe aver processato l'audio")
            print("\nüìù Controlla i log del server per vedere:")
            print("   - Trascrizione dell'audio")
            print("   - Risposta dell'AI")
            print("   - Invio della risposta audio a Twilio")
            
    except Exception as e:
        print(f"‚ùå Errore durante il test: {e}")
        return False
    
    return True

if __name__ == "__main__":
    print("‚ö†Ô∏è  IMPORTANTE: Assicurati di aver configurato OPENAI_API_KEY nel file .env")
    print("Avvia il server con: python3 -m uvicorn main:app --reload --host 0.0.0.0 --port 8000")
    print("Poi esegui questo script in un altro terminale.\n")
    
    success = asyncio.run(test_openai_integration())
    
    if success:
        print("\n‚úÖ TEST OPENAI COMPLETATO!")
    else:
        print("\n‚ùå Test fallito. Controlla la configurazione.")
